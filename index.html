<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Qinyu Yang</title>

    <meta name="author" content="Qinyu Yang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Qinyu Yang
                </p>
                <p>
		Hi ðŸ‘‹.
		I am currently a master student at <a href="https://www.dlut.edu.cn/">Dalian University of Technology</a>, supervised by <a href="https://scholar.google.com/citations?user=ycFs33AAAAAJ&hl=en">Prof. Zhixun Su</a>.
                </p>
                <p>
                  My main research focus is text-to-image/video generation. I am also working at other Diffusion-related research.
                </p>
                <p style="text-align:center">
                  <a href="yangqinyu1110@163.com">Email</a> &nbsp;/&nbsp;
<!--                   <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp; -->
                  <a href="https://github.com/yangqy1110/">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:30%;max-width:30%">
                <a href="images_y/yangqy.jpg"><img style="width:80%;max-width:80%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images_y/yangqy.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Publications</h2>
                <p>
                  Some of the papers in which I was a core participant are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


      <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <video  width=100% height=100% muted autoplay loop>
            <source src="images_y/NC-SDEdit.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://yangqy1110.github.io/NC-SDEdit/">
            <span class="papertitle">Noise Calibration: Plug-and-play Content-Preserving Video Enhancement using Pre-trained Video Diffusion Models</span>
          </a>
          <br>
          <!-- <a href="https://bmild.github.io/">Ben Mildenhall</a>,
          <a href="https://phogzone.com/">Peter Hedman</a>,
          <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>, <br>
          <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>, -->
          <strong>Qinyu Yang</strong>,
	  <a href="https://scholar.google.com/citations?user=6UPJSvwAAAAJ&hl=zh-CN" target="_blank">Haoxin Chen</a>,
	  <a href="https://yzhang2016.github.io" target="_blank">Yong Zhang</a>,
	  <a href="https://menghanxia.github.io/" target="_blank">Menghan Xia</a>,
          <a href="http://vinthony.github.io/" target="_blank">Xiaodong Cun</a>,
	  <a href="https://scholar.google.com/citations?user=ycFs33AAAAAJ&hl=en" target="_blank">Zhixun Su</a>,
          <a href="https://scholar.google.com/citations?hl=zh-CN&user=4oXBp9UAAAAJ" target="_blank">Ying Shan</a>
          <br>
          <em>ECCV</em>, 2024 &nbsp
          <br>
          <a href="https://yangqy1110.github.io/NC-SDEdit/">Project page</a> / 
          <a href="https://arxiv.org/abs/2407.10285">arXiv</a> / 
          <a href="https://github.com/yangqy1110/NC-SDEdit">Github</a>
          <p></p>
          <p>
            Plug-and-play video enhancement model based on pre-trained diffusion model.
          </p>
        </td>
      </tr> 	

      <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images_y/MGDM.png' width="100%">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://ieeexplore.ieee.org/abstract/document/10530514">
            <span class="papertitle">Measurement Guidance in Diffusion Models: Insight from Medical Image Synthesis</span>
          </a>
          <br>
          <font style="color: #1772d0;">Yimin Luo*, </font> &nbsp;
          <strong>Qinyu Yang*</strong>,
          <font style="color: #1772d0;">Yuheng Fan, </font> &nbsp;
          <font style="color: #1772d0;">Haikun Qi, </font> &nbsp;
	  <font style="color: #1772d0;">Menghan Xia, </font> &nbsp;
          <br>
          <em>TPAMI</em>, 2024
<!--           <em>ACM MM</em>, 2021 &nbsp <font color="red"><strong>(Oral)</strong></font> -->
          <br>
<!--           <a href="https://arxiv.org/abs/2308.08730">arXiv</a> /  -->
          <a href="https://github.com/yangqy1110/MGDM">Github</a>
          <p></p>
          <p>We introduce uncertainty into the sampling process of the Diffusion Model and expand the Classifier-guided Method to generate samples that are more suitable for data augmentation in classification tasks.
          </p>
        </td>
      </tr>
		  
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images_y/DDIB.png' width="100%">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://ieeexplore.ieee.org/abstract/document/10508481">
            <span class="papertitle">Target-Guided Diffusion Models for Unpaired Cross-Modality Medical Image Translation</span>
          </a>
          <br>
          <font style="color: #1772d0;">Yimin Luo, </font> &nbsp;
          <strong>Qinyu Yang</strong>,
          <font style="color: #1772d0;">Ziyi Liu, </font> &nbsp;
          <font style="color: #1772d0;">Zenglin Shi, </font> &nbsp;
	  <font style="color: #1772d0;">Weimin Huang, </font> &nbsp;
          <font style="color: #1772d0;">Guoyan Zheng, </font> &nbsp;
	  <font style="color: #1772d0;">Jun Cheng, </font> &nbsp;
          <br>
          <em>IEEE Journal of Biomedical and Health Informatics (IF:6.7)</em>, 2024
<!--           <em>ACM MM</em>, 2021 &nbsp <font color="red"><strong>(Oral)</strong></font> -->
          <br>
<!--           <a href="https://ieeexplore.ieee.org/abstract/document/10508481/authors#authors">paper</a> -->
          <p></p>
          <p>Diffusion Model for Image Translation. We propose a target-guided diffusion model for unpaired cross-modal medical image translation.
          </p>
        </td>
		  
      <tr bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src='images_y/C2F-DFT.png' width="100%">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://github.com/wlydlut/C2F-DFT">
            <span class="papertitle">Learning A Coarse-to-Fine Diffusion Transformer for Image Restoration</span>
          </a>
          <br>
          <font style="color: #1772d0;">Liyan Wang, </font> &nbsp;
          <strong>Qinyu Yang</strong>,
          <font style="color: #1772d0;">Cong Wang, </font> &nbsp;
          <font style="color: #1772d0;">Wei Wang, </font> &nbsp;
	  <font style="color: #1772d0;">Zhixun Su, </font> &nbsp;
          <br>
          <em>arXiv</em>, 2023
<!--           <em>ACM MM</em>, 2021 &nbsp <font color="red"><strong>(Oral)</strong></font> -->
          <br>
          <a href="https://arxiv.org/abs/2308.08730">arXiv</a> / 
          <a href="https://github.com/wlydlut/C2F-DFT">Github</a>
          <p></p>
          <p>Diffusion Model for Image Restoration. We refer to DIT and Restormer to come up with a network architecture for image restoration and design a training process for image restoration.
          </p>
        </td>
      </tr>
            
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  <!-- Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page. -->
                  Webpage templete is borrowed from <a href="https://github.com/jonbarron/jonbarron_website">this</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
